{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eec8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# yahoo finance data downloader.\n",
    "#https://pypi.org/project/yfinance/0.2.3/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffcc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_backward(days):\n",
    "    tod = datetime.now()\n",
    "    dlt = timedelta(days = days)\n",
    "    newd = (tod - dlt).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    return newd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29d111b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(TICKER, CSV_POSTFIX, INTERVAL,YFINTERVAL,DDLT):\n",
    "    ticker = TICKER\n",
    "    csv_postfix = CSV_POSTFIX\n",
    "    # interval -- hourly | daily | weekly | monthly\n",
    "    interval = INTERVAL\n",
    "    # interval in yahoo finance\n",
    "    yfinterval = YFINTERVAL\n",
    "    # datetime delta\n",
    "    ddlt = DDLT\n",
    "    \n",
    "    csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + csv_postfix\n",
    "    if os.path.exists(csv_file):\n",
    "        if interval == 'hourly':\n",
    "            stock_df = pd.read_csv(csv_file, parse_dates = ['Datetime'], index_col = ['Datetime'])\n",
    "        else:\n",
    "            stock_df = pd.read_csv(csv_file, parse_dates = ['Date'], index_col = ['Date'])\n",
    "            \n",
    "        max_date = stock_df.index.max()\n",
    "        #print(max_date)\n",
    "        start_date = max_date.date() + timedelta(days=ddlt)\n",
    "        #print(start_date)\n",
    "\n",
    "        if start_date > datetime.now().date():\n",
    "            print(\"{} {} data is up to date.\".format(ticker, interval))\n",
    "        else:\n",
    "            # Retrieve new hourly data and append to csv file.\n",
    "            new_data = pdr.get_data_yahoo(ticker, start=start_date,interval=yfinterval)\n",
    "            new_data.to_csv(csv_file, mode='a', index=True, header=False)\n",
    "            print(\"{} {} data appended to the file: {}\".format(ticker, interval, csv_file))\n",
    "    else:\n",
    "        # create new csv file.\n",
    "        csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_h.csv'\n",
    "        if interval == 'hourly':\n",
    "            # retrieve hourly data\n",
    "            data = pdr.get_data_yahoo(ticker, start=get_date_backward(720),interval=yfinterval)\n",
    "        else:\n",
    "            # retrieve daily/weekly/monthly data\n",
    "            data = pdr.get_data_yahoo(ticker, start=\"2000-01-01\",interval=yfinterval)\n",
    "            \n",
    "        data.to_csv(csv_file)\n",
    "        print(\"{} {} data saved to the file: {}\".format(ticker, interval, csv_file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c4dedf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving data for 0981.hk.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "0981.hk hourly data appended to the file: data\\_981_h.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "0981.hk daily data appended to the file: data\\_981_d.csv\n",
      "0981.hk weekly data is up to date.\n",
      "0981.hk monthly data is up to date.\n",
      "\n",
      "Retrieving data for 2202.hk.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2202.hk hourly data appended to the file: data\\_2202_h.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "2202.hk daily data appended to the file: data\\_2202_d.csv\n",
      "2202.hk weekly data is up to date.\n",
      "2202.hk monthly data is up to date.\n",
      "\n",
      "Retrieving data for 0020.hk.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "0020.hk hourly data appended to the file: data\\_20_h.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "0020.hk daily data appended to the file: data\\_20_d.csv\n",
      "0020.hk weekly data is up to date.\n",
      "0020.hk monthly data is up to date.\n",
      "\n",
      "Retrieving data for 9888.hk.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "9888.hk hourly data appended to the file: data\\_9888_h.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "9888.hk daily data appended to the file: data\\_9888_d.csv\n",
      "9888.hk weekly data is up to date.\n",
      "9888.hk monthly data is up to date.\n",
      "\n",
      "Retrieving data for 6862.hk.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "6862.hk hourly data appended to the file: data\\_6862_h.csv\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "6862.hk daily data appended to the file: data\\_6862_d.csv\n",
      "6862.hk weekly data is up to date.\n",
      "6862.hk monthly data is up to date.\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "\n",
    "yf.pdr_override() \n",
    "#data = pdr.get_data_yahoo(\"0371.hk\", start=\"2017-01-01\", end=\"2023-01-07\")\n",
    "\n",
    "# Holdings\n",
    "tickers1 = ['0788.hk','0371.hk','1093.hk','6837.hk','0357.hk']\n",
    "\n",
    "# Tech\n",
    "tickers2 = ['6060.hk','1951.hk','1833.hk','0241.hk','0354.hk']\n",
    "# Others\n",
    "tickers3 = ['0981.hk','2202.hk','0020.hk','9888.hk','6862.hk']\n",
    "# ETF\n",
    "tickers4 = ['2828.hk','2822.hk','3032.HK',]\n",
    "# Telcom.\n",
    "tickers5 = ['0941.hk','0762.hk','0728.hk','0788.hk']\n",
    "\n",
    "tickers = tickers1 + tickers2 + tickers3 + tickers4 + tickers5\n",
    "tickers = tickers3\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Retrieve new hourly data.\n",
    "    print(\"\\nRetrieving data for {}.\".format(ticker))\n",
    "    retrieve_data(ticker, '_h.csv','hourly','1h',1)\n",
    "    \n",
    "    # Retrieve new daily data.\n",
    "    retrieve_data(ticker, '_d.csv','daily','1d',1)\n",
    "    \n",
    "    # Retrieve new weekly data.\n",
    "    retrieve_data(ticker, '_w.csv','weekly','1wk',7)\n",
    "    \n",
    "    # Retrieve new monthly data.\n",
    "    retrieve_data(ticker, '_m.csv','monthly','1mo',30)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbaa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_h.csv'\n",
    "#     if os.path.exists(csv_file):\n",
    "#         stock_df = pd.read_csv(csv_file, parse_dates = ['Datetime'], index_col = ['Datetime'])\n",
    "#         max_date = stock_df.index.max()\n",
    "#         #print(max_date)\n",
    "#         start_date = max_date.date() + timedelta(days=1)\n",
    "#         #print(start_date)\n",
    "\n",
    "#         if start_date > datetime.now().date():\n",
    "#             print(\"{} data is up to date.\".format(ticker))\n",
    "#         else:\n",
    "#             # Retrieve new hourly data and append to csv file.\n",
    "#             print(\"Retrieving data for {}.\".format(ticker))\n",
    "#             new_data = pdr.get_data_yahoo(ticker, start=start_date,interval='1h')\n",
    "#             new_data.to_csv(csv_file, mode='a', index=True, header=False)\n",
    "#             print(\"Hourly data saved to the file:\",csv_file)\n",
    "#     else\n",
    "#         # create new csv file for hourly data.\n",
    "#         print(\"retrieving data for {}.\".format(ticker))\n",
    "#         # retrieve hourly data\n",
    "#         csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_h.csv'\n",
    "#         data = pdr.get_data_yahoo(ticker, start=get_date_backward(720),interval='1h')\n",
    "#         data.to_csv(csv_file)\n",
    "        \n",
    "        \n",
    "#     # Retrieve new daily data.\n",
    "#     csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_d.csv'\n",
    "#     if os.path.exists(csv_file):\n",
    "#         stock_df = pd.read_csv(csv_file, parse_dates = ['Date'], index_col = ['Date'])\n",
    "#         max_date = stock_df.index.max()\n",
    "#         print(max_date)\n",
    "#         start_date = max_date.date() + timedelta(days=1)\n",
    "#         print(start_date)\n",
    "\n",
    "#         if start_date > datetime.now().date():\n",
    "#             print(\"{} data is up to date.\".format(ticker))\n",
    "#         else:\n",
    "#             # Retrieve new daily data and append to csv file.\n",
    "#             new_data = pdr.get_data_yahoo(ticker, start=start_date,interval='1d')\n",
    "#             new_data.to_csv(csv_file, mode='a', index=True, header=False)\n",
    "#             print(\"Daily data saved to the file:\",csv_file)\n",
    "#     else:\n",
    "#         # create new csv file for daily data.\n",
    "#         print(\"retrieving data for {}.\".format(ticker))\n",
    "#         data = pdr.get_data_yahoo(ticker, start=\"2000-01-01\",interval='1d')\n",
    "#         data.to_csv(csv_file)\n",
    "#         print(\"Daily data saved to the file:\",csv_file)\n",
    "        \n",
    "#     # Retrieve weekly data\n",
    "#     csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_w.csv'\n",
    "#     if os.path.exists(csv_file):\n",
    "#         stock_df = pd.read_csv(csv_file, parse_dates = ['Date'], index_col = ['Date'])\n",
    "#         max_date = stock_df.index.max()\n",
    "#         print(max_date)\n",
    "#         start_date = max_date.date() + timedelta(days=7)\n",
    "#         print(start_date)\n",
    "\n",
    "#         if start_date > datetime.now().date():\n",
    "#             print(\"{} data is up to date.\".format(ticker))\n",
    "#         else:\n",
    "#             # Retrieve weekly data and append to csv file.\n",
    "#             new_data = pdr.get_data_yahoo(ticker, start=start_date,interval='1wk')\n",
    "#             new_data.to_csv(csv_file, mode='a', index=True, header=False)\n",
    "#             print(\"Weekly data saved to the file:\",csv_file)\n",
    "#     else:\n",
    "#         # create new csv file for weekly data.\n",
    "#         print(\"retrieving data for {}.\".format(ticker))\n",
    "#         data = pdr.get_data_yahoo(ticker, start=\"2000-01-01\",interval='1wk')\n",
    "#         data.to_csv(csv_file)\n",
    "#         print(\"Weekly data saved to the file:\",csv_file)\n",
    "        \n",
    "#     # Retrieve new monthly data\n",
    "#     csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_m.csv'\n",
    "#     if os.path.exists(csv_file):\n",
    "#         stock_df = pd.read_csv(csv_file, parse_dates = ['Date'], index_col = ['Date'])\n",
    "#         max_date = stock_df.index.max()\n",
    "#         print(max_date)\n",
    "#         start_date = max_date.date() + timedelta(days=30)\n",
    "#         print(start_date)\n",
    "\n",
    "#         if start_date > datetime.now().date():\n",
    "#             print(\"{} data is up to date.\".format(ticker))\n",
    "#         else:\n",
    "#             # Retrieve weekly data and append to csv file.\n",
    "#             new_data = pdr.get_data_yahoo(ticker, start=start_date,interval='1mo')\n",
    "#             new_data.to_csv(csv_file, mode='a', index=True, header=False)\n",
    "#             print(\"Monthly data saved to the file:\",csv_file)\n",
    "#     else:\n",
    "#         # create new csv file for weekly data.\n",
    "#         print(\"retrieving data for {}.\".format(ticker))\n",
    "#         csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_m.csv'       \n",
    "#         data = pdr.get_data_yahoo(ticker, start=\"2000-01-01\",interval='1mo')\n",
    "#         data.to_csv(csv_file)\n",
    "#         print(\"Monthly data saved to the file:\",csv_file)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Assume 'data' is a list of dictionaries with a 'date' field\n",
    "data = [ '2023-02-07', '2023-02-06' ]\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "for row in data:\n",
    "    row = datetime.datetime.strptime(row, '%Y-%m-%d')\n",
    "\n",
    "# Sort data by date\n",
    "data.sort()\n",
    "print(data)\n",
    "\n",
    "# Keep the first record in each week\n",
    "previous_week = None\n",
    "records_to_keep = []\n",
    "for row in data:\n",
    "    if previous_week is None or row.isocalendar()[1] != previous_week:\n",
    "        records_to_keep.append(row)\n",
    "        previous_week = row.isocalendar()[1]\n",
    "\n",
    "# # Remove the rest of the records\n",
    "data = records_to_keep\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker in tickers:\n",
    "#     data = pdr.get_data_yahoo(ticker, start=\"2022-01-01\",interval='1h')\n",
    "#     csv_file = \"data\\\\\" + '_' + ticker.lstrip(\"0\").split(\".\")[0] + '_h.csv'\n",
    "#     data.to_csv(csv_file)\n",
    "#     print(\"Daily data saved to the file:\",csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c29a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_code = 'DGS10' # 10-year Treasury Rate\n",
    "# data_source = 'fred' # FED Economic Data Service\n",
    "# start = date(1962, 1, 1)\n",
    "# data = DataReader(series_code, data_source, start)\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# msft = yf.Ticker(\"MSFT\")\n",
    "# msft.info\n",
    "# msft.recommendations_summary\n",
    "# msft.institutional_holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f4625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_data = pd.read_csv('data\\_371.csv', parse_dates = ['Date'], index_col = ['Date'])\n",
    "# stock_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = ( stock_data.index  > '1/1/2018' )\n",
    "# stock_data = pd.read_csv('data\\_371.csv', parse_dates = ['Date'], index_col = ['Date'])\n",
    "# df = stock_data[mask]\n",
    "# df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
